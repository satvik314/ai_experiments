{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik314/ai_experiments/blob/main/QA_on_Docs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Docx Reader - pypdf\n",
        "* VectorDB - FAISS\n",
        "* Embeddings - OpenAI\n",
        "* Model - OpenAI"
      ],
      "metadata": {
        "id": "j-Fuo1D0Pt5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain docx2txt pypdf openai prompts faiss-cpu tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYIcF38CN6wg",
        "outputId": "3d7954b6-76ff-4536-c5a3-68d03f97e7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.9/dist-packages (0.0.141)\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.9/dist-packages (0.8)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.9/dist-packages (3.8.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.4)\n",
            "Requirement already satisfied: prompts in /usr/local/lib/python3.9/dist-packages (0.0.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.9/dist-packages (1.7.3)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.4.47)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.9/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: gptcache>=0.1.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.1.11)\n",
            "Requirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from pypdf) (4.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.9/dist-packages (from gptcache>=0.1.7->langchain) (5.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_F3UAUCM9GA"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.utils import get_from_dict_or_env\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.vectorstores import FAISS, VectorStore\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import docx2txt\n",
        "from typing import List, Dict, Any\n",
        "import os\n",
        "import re\n",
        "import faiss\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "from io import BytesIO\n",
        "from pypdf import PdfReader\n",
        "from openai.error import AuthenticationError"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"]=input(\"Paste the key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz7pCnB0Sefd",
        "outputId": "2af998c9-6647-4080-89aa-0ec7f4aa8e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste the key: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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading a pdf file and converting to text\n",
        "def pdf_reader(file: BytesIO) -> List[str]:\n",
        "    pdf = PdfReader(file)\n",
        "    output = []\n",
        "    for page in pdf.pages:\n",
        "        text = page.extract_text()\n",
        "        # Merge hyphenated words\n",
        "        text = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", text)\n",
        "        # Fix newlines in the middle of sentences\n",
        "        text = re.sub(r\"(?<!\\n\\s)\\n(?!\\s\\n)\", \" \", text.strip())\n",
        "        # Remove multiple newlines\n",
        "        text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
        "\n",
        "        output.append(text)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "ex-8n3KbNlGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_docs(text: str) -> List[Document]:\n",
        "    \"\"\"Converts a string or list of strings to a list of Documents\n",
        "    with metadata.\"\"\"\n",
        "    if isinstance(text, str):\n",
        "        # Take a single string as one page.\n",
        "        text = [text]\n",
        "    page_docs = [Document(page_content=page) for page in text]\n",
        "\n",
        "    # Add page numbers as metadata\n",
        "    for i, doc in enumerate(page_docs):\n",
        "        doc.metadata[\"page\"] = i + 1\n",
        "\n",
        "    # Split pages into chunks\n",
        "    doc_chunks = []\n",
        "\n",
        "    for doc in page_docs:\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=800,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
        "            chunk_overlap=0,\n",
        "        )\n",
        "        chunks = text_splitter.split_text(doc.page_content)\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            doc = Document(\n",
        "                page_content=chunk, metadata={\"page\": doc.metadata[\"page\"], \"chunk\": i}\n",
        "            )\n",
        "            # Add sources a metadata\n",
        "            doc.metadata[\"source\"] = f\"{doc.metadata['page']}-{doc.metadata['chunk']}\"\n",
        "            doc_chunks.append(doc)\n",
        "    return doc_chunks"
      ],
      "metadata": {
        "id": "hGifqBdqP5Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_docs(docs: List[Document]) -> VectorStore:\n",
        "    \"\"\"Embeds a list of Documents and returns a FAISS index\"\"\"\n",
        "        # Embed the chunks\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    index = FAISS.from_documents(docs, embeddings)\n",
        "    #Saving the Vectorstore\n",
        "    index.save_local(\"Embeddings_db\")\n",
        "    return index"
      ],
      "metadata": {
        "id": "U0dMUdxWSC3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Use a shorter template to reduce the number of tokens in the prompt\n",
        "query_template = \"\"\"Create a final answer to the given questions using the provided document excerpts(in no particular order) as references and also answer based on the chat history.\n",
        "---------\n",
        "QUESTION: What  is the purpose of ARPA-H?\n",
        "=========\n",
        "Content: More support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more.\n",
        "Source: 1-32\n",
        "Content: While we’re at it, let’s make sure every American can get the health care they need. \\n\\nWe’ve already made historic investments in health care. \\n\\nWe’ve made it easier for Americans to get the care they need, when they need it. \\n\\nWe’ve made it easier for Americans to get the treatments they need, when they need them. \\n\\nWe’ve made it easier for Americans to get the medications they need, when they need them.\n",
        "Source: 1-33\n",
        "Content: The V.A. is pioneering new ways of linking toxic exposures to disease, already helping  veterans get the care they deserve. \\n\\nWe need to extend that same care to all Americans. \\n\\nThat’s why I’m calling on Congress to pass legislation that would establish a national registry of toxic exposures, and provide health care and financial assistance to those affected.\n",
        "Source: 1-30\n",
        "=========\n",
        "FINAL ANSWER: The purpose of ARPA-H is to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more.\n",
        "---------\n",
        "{chat_history}\n",
        "QUESTION: {question}\n",
        "=========\n",
        "{summaries}\n",
        "=========\n",
        "FINAL ANSWER:\"\"\"\n",
        "\n",
        "STUFF_PROMPT = PromptTemplate(\n",
        "    template=query_template, input_variables=[\"chat_history\",\"summaries\", \"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "7v-8oKE2Vw6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contents_template = '''Please give the main topics of the following document: {document} in the following format\n",
        "Main heading\n",
        "- Subheading 1\n",
        "- Subheading 2\n",
        "- Subheading 3\n",
        "... '''\n",
        "\n",
        "# Function to produce topics and subtopics from the document.\n",
        "def get_contents(docs: List[Document]):\n",
        "    prompt = PromptTemplate(\n",
        "    input_variables=[\"document\"],\n",
        "    template= contents_template,\n",
        ")\n",
        "\n",
        "    document_content = \"Your document content here\"\n",
        "    formatted_prompt = prompt.format(document=docs)\n",
        "    llm = OpenAI(temperature=0)\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    response = chain({'document': docs}, return_only_outputs = True)\n",
        "    return response"
      ],
      "metadata": {
        "id": "CImU4PQMOIty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_docs(index: VectorStore, query: str) -> List[Document]:\n",
        "    \"\"\"Searches a FAISS index for similar chunks to the query\n",
        "    and returns a list of Documents.\"\"\"\n",
        "    # Search for similar chunks. k determines the number of nearest neighbours\n",
        "    # Number of k also impacts the number of tokens passing to the prompt\n",
        "    docs = index.similarity_search(query, k=3)\n",
        "    return docs\n"
      ],
      "metadata": {
        "id": "Vna9eJpITIO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(docs: List[Document], query: str) -> Dict[str, Any]:\n",
        "    \"\"\"Gets an answer to a question from a list of Documents.\"\"\"\n",
        "\n",
        "    #Adding a memory\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\")\n",
        "\n",
        "    chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\",memory=memory, prompt=STUFF_PROMPT)\n",
        "    # retrievalQA = RetrievalQA.from_llm(llm=OpenAI(), retriever=index)\n",
        "\n",
        "    answer = chain(\n",
        "        {\"input_documents\": docs, \"question\": query}, return_only_outputs=True\n",
        "    )\n",
        "    return answer"
      ],
      "metadata": {
        "id": "utTVUH0iU-DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discard the function (Not currently in use)\n",
        "def get_sources(answer: Dict[str, Any], docs: List[Document]) -> List[Document]:\n",
        "    \"\"\"Gets the source documents for an answer.\"\"\"\n",
        "\n",
        "    # Get sources for the answer\n",
        "    source_keys = [s for s in answer[\"output_text\"].split(\"SOURCES: \")[-1].split(\", \")]\n",
        "\n",
        "    source_docs = []\n",
        "    for doc in docs:\n",
        "        if doc.metadata[\"source\"] in source_keys:\n",
        "            source_docs.append(doc)\n",
        "\n",
        "    return source_docs"
      ],
      "metadata": {
        "id": "Kfh-G7EoVwMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_the_bot(pdf='/content/lawsofmotion.pdf'):\n",
        "  # Loading the vectorstore db if exists\n",
        "  if os.path.exists('/content/Embeddings_db'):\n",
        "    index = FAISS.load_local('/content/Embeddings_db',OpenAIEmbeddings())\n",
        "  else:\n",
        "    text = pdf_reader(pdf)\n",
        "    processed_txt = text_to_docs(text)\n",
        "    index = embed_docs(processed_txt)\n",
        "  # Producing topic list for only one portion of document.\n",
        "  text = pdf_reader(pdf)\n",
        "  processed_txt = text_to_docs(text)\n",
        "  print(\"Welcome to the File Chat Bot. Ask the bot anything about the context. Enter exit to exit the chat.\")\n",
        "  print(\"Do you want to show the contents of the document?\")\n",
        "  if input(\"Enter your respones\").lower()==\"yes\":\n",
        "    print(get_contents(processed_txt[0]))\n",
        "  while True:\n",
        "    query = input(\"Enter your query : \")\n",
        "    if query.lower()=='exit':\n",
        "      break\n",
        "    else:\n",
        "      sources = search_docs(index, query)\n",
        "      answer = get_answer(sources, query)\n",
        "      print(\"Bot : {}\".format(answer['output_text']))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TI7UqGfWW7O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask_the_bot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "HjUMo8gcpgpW",
        "outputId": "e0db9630-a2a2-4691-a857-5db07f742d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the File Chat Bot. Ask the bot anything about the context. Enter exit to exit the chat.\n",
            "Do you want to show the contents of the document?\n",
            "Enter your responesyes\n",
            "{'text': '\\n\\nMain heading: Motion and its Causes \\nSubheading 1: Motion Along a Straight Line \\nSubheading 2: Causes of Motion \\nSubheading 3: Natural State of an Object'}\n",
            "Enter your query : What is motion?\n",
            "Bot :  Motion is the natural tendency of objects to resist a change in their state of rest or of uniform motion. It is measured in terms of position, velocity and acceleration, and can be uniform or non-uniform. The rate of change of momentum of an object is proportional to the applied unbalanced force in the direction of the force.\n",
            "Enter your query : What is the first question that someone can ask?\n",
            "Bot :  The first question that someone can ask is: \"Which of the following has more inertia: (a) a rubber ball and a stone of the same size? (b) a bicycle and a train? (c) a five - rupees coin and a one-rupee coin?\"\n",
            "Enter your query : What is inertia? Give example\n",
            "Bot :  Inertia is the natural tendency of an object to resist a change in its state of motion or of rest. The mass of an object is a measure of its inertia. For example, it is easier to push an empty box than a box full of books, and if we kick a football it flies away, but if we kick a stone of the same size with equal force, it hardly moves.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-413a0fdacaa3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mask_the_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-8f42cdb84f07>\u001b[0m in \u001b[0;36mask_the_bot\u001b[0;34m(pdf)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_txt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your query : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_KHBtufuBwA-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}