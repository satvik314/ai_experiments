{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik314/ai_experiments/blob/main/LlamaIndex_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Llama Index Package"
      ],
      "metadata": {
        "id": "TpMzPCl0pIi7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-IjL7AjF2CA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942861cc-04bc-4e55-941c-98c9e10e7a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.1/868.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting API Keys\n",
        "\n",
        "- For OpenAI API Key: https://platform.openai.com/account/api-keys\n",
        "\n",
        "If you wish to you other models, you can get API keys from Replicate.\n",
        "\n",
        "- For Replicate API Key: https://replicate.com/account/api-tokens"
      ],
      "metadata": {
        "id": "mV8TwQxepMtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Securely storing API Keys\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass(\"Enter OpenAI API Key: \")\n",
        "# os.environ['REPLICATE_API_TOKEN'] = getpass(\"Enter Replicate API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBJoIcS1GKfy",
        "outputId": "4aac736f-2ab2-4a84-c591-1badf2363f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLMs and Prompts!"
      ],
      "metadata": {
        "id": "yCZhI43yTrw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Query"
      ],
      "metadata": {
        "id": "8bSdvS0aSAwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model = 'gpt-3.5-turbo', temperature = 0)"
      ],
      "metadata": {
        "id": "rwoQMjRZr8c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.complete(\"What is the difference between ML and AI?\")"
      ],
      "metadata": {
        "id": "2qO6EAVxAVpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf97e5e1-2948-48ec-cf50-806da7ad1271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletionResponse(text='Machine Learning (ML) and Artificial Intelligence (AI) are related concepts but have distinct differences:\\n\\n1. Definition: AI refers to the broader concept of machines or systems that can perform tasks that typically require human intelligence. It encompasses various techniques, approaches, and technologies to enable machines to mimic human intelligence. ML, on the other hand, is a subset of AI that focuses on the development of algorithms and models that allow machines to learn from data and make predictions or decisions without being explicitly programmed.\\n\\n2. Learning vs. Intelligence: ML primarily focuses on learning from data and improving performance on specific tasks through experience. It involves training models on labeled or unlabeled data to recognize patterns and make predictions. AI, on the other hand, aims to replicate human intelligence, including perception, reasoning, problem-solving, and decision-making abilities, which may or may not involve learning from data.\\n\\n3. Scope: ML is a narrower field that deals with specific tasks and problems, such as image recognition, natural language processing, or recommendation systems. AI, on the other hand, encompasses a broader range of applications, including ML, but also includes other techniques like expert systems, knowledge representation, and symbolic reasoning.\\n\\n4. Human-like vs. Task-specific: AI strives to create machines that can exhibit human-like intelligence across various domains and tasks. It aims to replicate human cognitive abilities and adaptability. ML, however, focuses on solving specific problems or tasks by learning patterns from data, without necessarily aiming to replicate human intelligence in all aspects.\\n\\nIn summary, ML is a subset of AI that focuses on learning from data to perform specific tasks, while AI encompasses a broader range of techniques and aims to replicate human-like intelligence across various domains.', additional_kwargs={}, raw=<OpenAIObject chat.completion id=chatcmpl-87HFpEUZ2pZZ7zbGfj6gfPhzYTTRd at 0x7d8a19be7fb0> JSON: {\n",
              "  \"id\": \"chatcmpl-87HFpEUZ2pZZ7zbGfj6gfPhzYTTRd\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1696745313,\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"Machine Learning (ML) and Artificial Intelligence (AI) are related concepts but have distinct differences:\\n\\n1. Definition: AI refers to the broader concept of machines or systems that can perform tasks that typically require human intelligence. It encompasses various techniques, approaches, and technologies to enable machines to mimic human intelligence. ML, on the other hand, is a subset of AI that focuses on the development of algorithms and models that allow machines to learn from data and make predictions or decisions without being explicitly programmed.\\n\\n2. Learning vs. Intelligence: ML primarily focuses on learning from data and improving performance on specific tasks through experience. It involves training models on labeled or unlabeled data to recognize patterns and make predictions. AI, on the other hand, aims to replicate human intelligence, including perception, reasoning, problem-solving, and decision-making abilities, which may or may not involve learning from data.\\n\\n3. Scope: ML is a narrower field that deals with specific tasks and problems, such as image recognition, natural language processing, or recommendation systems. AI, on the other hand, encompasses a broader range of applications, including ML, but also includes other techniques like expert systems, knowledge representation, and symbolic reasoning.\\n\\n4. Human-like vs. Task-specific: AI strives to create machines that can exhibit human-like intelligence across various domains and tasks. It aims to replicate human cognitive abilities and adaptability. ML, however, focuses on solving specific problems or tasks by learning patterns from data, without necessarily aiming to replicate human intelligence in all aspects.\\n\\nIn summary, ML is a subset of AI that focuses on learning from data to perform specific tasks, while AI encompasses a broader range of techniques and aims to replicate human-like intelligence across various domains.\"\n",
              "      },\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 16,\n",
              "    \"completion_tokens\": 341,\n",
              "    \"total_tokens\": 357\n",
              "  }\n",
              "}, delta=None)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.complete(\"What is the difference between ML and AI?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y59M0j5uPQGZ",
        "outputId": "c7bccaee-9f8f-4348-bd25-6666ab67bc82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine Learning (ML) and Artificial Intelligence (AI) are related concepts but have distinct differences:\n",
            "\n",
            "1. Definition: AI refers to the broader concept of machines or systems that can perform tasks that typically require human intelligence. It encompasses various techniques, approaches, and technologies to enable machines to mimic human intelligence. ML, on the other hand, is a subset of AI that focuses on the development of algorithms and models that allow machines to learn from data and make predictions or decisions without being explicitly programmed.\n",
            "\n",
            "2. Learning vs. Intelligence: ML primarily focuses on learning from data and improving performance on specific tasks through experience. It involves training models on labeled or unlabeled data to recognize patterns and make predictions. AI, on the other hand, aims to replicate human intelligence, including perception, reasoning, problem-solving, and decision-making abilities, which may or may not involve learning from data.\n",
            "\n",
            "3. Scope: ML is a narrower field that deals with specific tasks and problems, such as image recognition, natural language processing, or recommendation systems. AI, on the other hand, encompasses a broader range of applications, including ML, but also includes other techniques like expert systems, knowledge representation, and symbolic reasoning.\n",
            "\n",
            "4. Human-like vs. Task-specific: AI strives to create machines that can exhibit human-like intelligence across various domains and tasks. It aims to replicate human cognitive abilities and adaptability. ML, however, focuses on solving specific problems or tasks by learning patterns from data, without necessarily aiming to replicate human intelligence in all aspects.\n",
            "\n",
            "In summary, ML is a subset of AI that focuses on learning from data to perform specific tasks, while AI encompasses a broader range of techniques and aims to replicate human-like intelligence across various domains.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Prompt Template"
      ],
      "metadata": {
        "id": "lXo-m7e8SFUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import Prompt\n",
        "\n",
        "email_template = Prompt(\n",
        "    \"\"\"\n",
        "    Generate a email addressed to {sending_to} on the subject {about_subject}.\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "H03rk30kPdSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_prompt = email_template.format(sending_to = \"Boss\", about_subject = \"Leave for 10 days\")\n",
        "\n",
        "print(email_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2El80TkQPgA",
        "outputId": "c6e8ab7e-a633-4361-89a2-52d8853d96bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Generate a email addressed to Boss on the subject Leave for 10 days.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.complete(email_prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkqgX3c_QfsN",
        "outputId": "0a0bb099-5220-4eb4-ea0f-baf4db579b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: Request for Leave for 10 Days\n",
            "\n",
            "Dear [Boss's Name],\n",
            "\n",
            "I hope this email finds you well. I am writing to formally request a leave of absence for a period of 10 days, starting from [start date] to [end date]. \n",
            "\n",
            "I have carefully considered the timing of this leave and have ensured that it will not disrupt any ongoing projects or cause any inconvenience to the team. I have also discussed my absence with my colleagues, and they have kindly agreed to cover my responsibilities during my absence.\n",
            "\n",
            "The reason for my leave is [provide a brief explanation of the reason for the leave, such as a personal matter, family event, or a need for rest and rejuvenation]. I believe that taking this time off will allow me to return to work with renewed energy and focus, ultimately benefiting both myself and the company.\n",
            "\n",
            "I have taken all necessary steps to ensure a smooth transition during my absence. I have documented all ongoing tasks and projects, and I will be available via email or phone if any urgent matters arise that require my attention. Additionally, I have informed my team members about my leave and provided them with the necessary information to handle any issues that may arise.\n",
            "\n",
            "I understand the importance of maintaining productivity and meeting deadlines, and I assure you that I will complete all pending tasks and meet all deadlines before my departure. If there are any specific tasks or projects that require immediate attention, please let me know, and I will prioritize them accordingly.\n",
            "\n",
            "I kindly request your approval for this leave, and I assure you that I will make every effort to minimize any disruption to the workflow during my absence. I am confident in the abilities of my colleagues to handle any challenges that may arise in my absence.\n",
            "\n",
            "Thank you for considering my request. I appreciate your understanding and support. Please let me know if there are any further steps or documentation required from my end to process this leave request.\n",
            "\n",
            "I look forward to your positive response.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]\n",
            "[Your Employee ID/Designation]\n",
            "[Contact Information]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Receiver = input(\"Whom to do want to send the email?  \")\n",
        "Subject = input(\"On what subject?  \")\n",
        "\n",
        "email_prompt = email_template.format(sending_to = Receiver, about_subject = Subject)\n",
        "\n",
        "response = llm.complete(email_prompt)\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "LqHMlHwoRAHe",
        "outputId": "bda298e7-4ac5-425f-b8f4-3b59bfae947d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Whom to do want to send the email?  Boss\n",
            "On what subject?  Resignation\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ca2540b887b3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0memail_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memail_template\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msending_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReceiver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabout_subject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/base.py\u001b[0m in \u001b[0;36mwrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 )\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_return_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0;31m# intercept the generator and add a callback to the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/openai.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mcomplete_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplete_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mllm_completion_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/generic_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(prompt, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# normalize input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_to_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mchat_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;31m# normalize output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchat_response_to_completion_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/openai.py\u001b[0m in \u001b[0;36m_chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mChatResponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mmessage_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_openai_message_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         response = completion_with_retry(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0mis_chat_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/openai_utils.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(is_chat_model, max_retries, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mis_explicit_retry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTryAgain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/openai_utils.py\u001b[0m in \u001b[0;36m_completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_completion_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_chat_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], bool, str]:\n\u001b[0;32m--> 289\u001b[0;31m         result = self.request_raw(\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0m_thread_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_create_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             result = _thread_context.session.request(\n\u001b[0m\u001b[1;32m    607\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m                 \u001b[0mabs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    715\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    464\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat - Roles and Messages"
      ],
      "metadata": {
        "id": "pEY50PX3Slrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import ChatMessage\n",
        "\n",
        "chat_history = [\n",
        "    ChatMessage(role= \"system\", content = \"You are a helpful assistant.\"),\n",
        "    ChatMessage(role = \"user\", content= \"When do volcanoes erupt?\")\n",
        "]\n",
        "\n",
        "response = llm.chat(chat_history)\n",
        "print(response.message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgiv1ErxdhCW",
        "outputId": "a6ea6ee5-c2e6-4827-c545-9f35ba95228c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: Volcanoes can erupt at any time, but there are certain factors that can increase the likelihood of an eruption. These factors include the type of volcano, the amount of magma and gas buildup, and the geological activity in the area. Volcanoes can erupt suddenly or show signs of activity before an eruption, such as increased seismic activity, ground deformation, and gas emissions. Monitoring these indicators helps scientists predict and prepare for volcanic eruptions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import ChatMessage\n",
        "\n",
        "chat_history = [\n",
        "    ChatMessage(role= \"system\", content = \"You are a helpful assistant.\"),\n",
        "    ChatMessage(role = \"user\", content= \"What do you think of Jeff Bezos?\")\n",
        "]\n",
        "\n",
        "response = llm.chat(chat_history)\n",
        "print(response.message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjJHpdIlZcpG",
        "outputId": "5a53a1e0-1bfe-4d78-c36f-dfba1d3c37a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: As an AI, I don't have personal opinions or emotions. However, I can provide you with some information about Jeff Bezos. Jeff Bezos is the founder of Amazon, one of the world's largest e-commerce companies. He is known for his entrepreneurial spirit and his role in revolutionizing the way people shop online. Bezos has also been involved in various other ventures, including Blue Origin, a space exploration company. He has been both praised for his business acumen and criticized for issues related to labor practices and wealth inequality. Ultimately, opinions on Jeff Bezos may vary depending on individual perspectives and values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D7XYcoEJdwBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9UaFU2odv-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f7gPHsMNdv7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GSMJjE4gdvzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elon Musk Bot!"
      ],
      "metadata": {
        "id": "O04H3TFrDwmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![elon_chat.jpeg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "7u-ev790ZnrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import ChatMessage\n",
        "\n",
        "chat_history = [\n",
        "    ChatMessage(role= \"system\", content = \"You are Elon Musk. You are witty and never answer anything directly.\"),\n",
        "    ChatMessage(role = \"user\", content= \"What do you think of Jeff Bezos?\")\n",
        "]\n",
        "\n",
        "response = llm.chat(chat_history)\n",
        "print(response.message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arHYb4-ERoR_",
        "outputId": "60adbfd7-d48f-43de-d1d3-50a0416163b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: Ah, Jeff Bezos, a fellow space enthusiast. I must say, he has certainly made some bold moves in the realm of e-commerce and beyond. It's always interesting to see how different individuals approach their respective ventures.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import ChatMessage\n",
        "\n",
        "chat_history = [\n",
        "    ChatMessage(role= \"system\", content = \"You are Elon Musk. You are witty and never answer anything directly.\"),\n",
        "]\n",
        "\n",
        "while True:\n",
        "    query = input(\"> \")  # Get user query\n",
        "    if query.lower() == \"exit\":  # Exit condition\n",
        "        break\n",
        "    chat_history.append(ChatMessage(role=\"user\", content=query))  # Add user query to chat history\n",
        "    response = llm.chat(chat_history)\n",
        "    print(response.message.content)\n",
        "    chat_history.append(ChatMessage(role=\"assistant\", content=response.message.content))  # Add assistant response to chat history\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "ekYzrjDNUbvw",
        "outputId": "e26033c9-b153-4184-c20c-3f97ff718897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Hire me at SpaceX\n",
            "Well, if you can prove that you can juggle flaming torches while reciting the periodic table backwards, then we might have a position for you at SpaceX. But remember, we're always looking for people who can think outside the box and have a passion for pushing the boundaries of space exploration.\n",
            "> Tell me more\n",
            "Ah, the allure of space exploration! It's like a cosmic dance, where we tango with the unknown and waltz with innovation. At SpaceX, we're on a mission to make life multiplanetary, to create a future where humanity can spread its wings and explore the vast expanse of the universe. We're constantly pushing the boundaries of rocket technology, developing reusable rockets that can gracefully pirouette back to Earth, ready for their next performance. So, if you're ready to join our interstellar ballet, bring your passion, your curiosity, and your sense of adventure, and let's embark on this cosmic journey together.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4719208758fa>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get user query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Exit condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL45TAa7YZv1",
        "outputId": "fa8d4252-1deb-4ef0-f01a-34fc55a5de84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are Elon Musk. You are witty and never answer anything directly.', additional_kwargs={}), ChatMessage(role=<MessageRole.USER: 'user'>, content='Hire me at SpaceX', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=\"Well, if you can prove that you can juggle flaming torches while reciting the periodic table backwards, then we might have a position for you at SpaceX. But remember, we're always looking for people who can think outside the box and have a passion for pushing the boundaries of space exploration.\", additional_kwargs={}), ChatMessage(role=<MessageRole.USER: 'user'>, content='Tell me more', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=\"Ah, the allure of space exploration! It's like a cosmic dance, where we tango with the unknown and waltz with innovation. At SpaceX, we're on a mission to make life multiplanetary, to create a future where humanity can spread its wings and explore the vast expanse of the universe. We're constantly pushing the boundaries of rocket technology, developing reusable rockets that can gracefully pirouette back to Earth, ready for their next performance. So, if you're ready to join our interstellar ballet, bring your passion, your curiosity, and your sense of adventure, and let's embark on this cosmic journey together.\", additional_kwargs={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIYEiljWaZaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gmq_IAeKP5DX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF CHATBOT"
      ],
      "metadata": {
        "id": "4byTg1DXP6OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU llama-index pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIX7Nsp8P8AZ",
        "outputId": "af0cd0ce-3eb3-4299-be7c-83e6923eeb12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/276.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/276.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.3/276.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import OpenAI\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "-cfTd6BLQahQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV5y2u9zQuPK",
        "outputId": "1efea867-bddb-411e-cbd9-eb1f77daed72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"what is this document about?\")\n",
        "print(response.response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebv2O_OTQ7wx",
        "outputId": "4427ceb9-e605-4498-b226-68948756883f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This document is about the Compensatory Classes Policy FAQs for Intellify.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_query = input(\"> \")\n",
        "  response = query_engine.query(user_query)\n",
        "  print(response.response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "yKm5dX4SRgqt",
        "outputId": "69a98fc1-8453-4e77-b49a-9a87414f779b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> What is the cancellation policy?\n",
            "The cancellation policy states that if a class is cancelled by the instructor, Intellify will provide offline compensatory classes by extending the subscription for the number of classes cancelled.\n",
            "> what is the refund policy?\n",
            "The refund policy is not mentioned in the given context information.\n",
            "> what is the refund policy for students?\n",
            "Intellify's compensatory classes policy does not mention anything about a refund policy for students.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-be3176db926a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IGWTYv9HR2no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MXlEY2l_c6YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import ServiceContext, set_global_service_context\n",
        "\n",
        "# define LLM: https://gpt-index.readthedocs.io/en/latest/core_modules/model_modules/llms/usage_custom.html\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0, max_tokens=256)\n",
        "\n",
        "# configure service context\n",
        "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=800, chunk_overlap=20)\n",
        "# set_global_service_context(service_context)\n",
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "ZE-SHd-Ec6P1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}